{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getpass, os\n",
    "from IPython import display\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = getpass.getuser()\n",
    "if user == \"sidsel\":\n",
    "    parquet_path = \"/home/sidsel/workspace/sparkdata/parquet\"\n",
    "elif user == \"svanhmic\":\n",
    "    parquet_path = \"/home/svanhmic/workspace/data/DABAI/sparkdata/parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classification.ExecuteClassificationWorkflow import ExecuteWorkflowClassification\n",
    "\n",
    "parameter_dict = selector.output_parameters(params)\n",
    "\n",
    "model = ExecuteWorkflowClassification(parameter_dict,\n",
    "                                      data_import.standardize,\n",
    "                                      data_import.list_features,\n",
    "                                      data_import.list_label\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = create_params.ParamsClassification()\n",
    "params = selector.select_parameters()\n",
    "display.display(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.output_parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = fitted_data.bestModel.stages[-1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(summary.areaUnderROC)\n",
    "print(summary.objectiveHistory)\n",
    "summary.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_str = '/home/svanhmic/workspace/data/DABAI/test.csv'\n",
    "#file_str = '/home/svanhmic/workspace/data/DABAI/test.txt'\n",
    "#parquet_str = '/home/svanhmic/workspace/data/DABAI/sparkdata/parquet/alleregnskaber.parquet'\n",
    "#json_str = '/home/svanhmic/workspace/data/DABAI/sparkdata/json/cdata-permanent.json'\n",
    "\n",
    "data_import = GeneralDataImport.GeneralDataImport(parquet_path+'/outlier_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_import.data_frame.show()\n",
    "#print(data_import.all_columns)\n",
    "#print(data_import.list_label)\n",
    "#print(data_import.list_features)\n",
    "print(list(map(lambda x: x.name, data_import.list_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Out[16]*2*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import.select_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "randUdf = F.udf(lambda x: 1.0 if x >= .5 else 0.0, T.DoubleType())\n",
    "\n",
    "\n",
    "df = data_import.data_frame\n",
    "#df.show(truncate=False)\n",
    "df.printSchema()\n",
    "df = df.withColumn('label',randUdf(F.rand()))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.create_dummy_data import make_outliers\n",
    "out_df = make_outliers(df, 0.5, 100)\n",
    "out_df.where(df.header_2=='NR.0972').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification import ExecuteClassificationWorkflow\n",
    "exclas = ExecuteClassificationWorkflow.ExecuteWorkflowClassification(Test,\n",
    "                                                                     False,\n",
    "                                                                     data_import.list_features,\n",
    "                                                                     data_import.list_label\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "cvm = exclas.run_cross_val(df, BinaryClassificationEvaluator(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm.transform(out_df).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
